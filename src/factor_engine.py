import pandas as pd
import numpy as np
from pathlib import Path
from src.config import DATA_DIR

class FactorEngine:
    def __init__(self):
        self.price_dir = DATA_DIR / "prices"
        self.fund_dir = DATA_DIR / "fundamentals"
        
    def run(self):
        """
        ä¸»æ‰§è¡Œå‡½æ•°ï¼šä»æ•°æ®åŠ è½½åˆ°å› å­è®¡ç®—çš„å…¨æµç¨‹
        """
        # 1. åŠ è½½æ‰€æœ‰æ•°æ®
        print("ğŸ“¥ æ­£åœ¨åŠ è½½ä»·æ ¼ä¸åŸºæœ¬é¢æ•°æ®...")
        df_panel = self._load_and_merge_data()
        
        if df_panel is None or df_panel.empty:
            print("âŒ æ•°æ®åŠ è½½å¤±è´¥æˆ–åˆå¹¶åä¸ºç©ºï¼Œæ— æ³•è®¡ç®—å› å­ã€‚")
            return None

        print(f"âœ… æ•°æ®åˆå¹¶æˆåŠŸ: å…± {len(df_panel)} æ¡è§‚æµ‹å€¼")

        # 2. è®¡ç®—æ¯æ—¥æ”¶ç›Šç‡
        # æŒ‰ç…§è‚¡ç¥¨ä»£ç åˆ†ç»„ï¼Œè®¡ç®— pct_change
        df_panel['ret'] = df_panel.groupby('symbol')['close'].pct_change()
        
        # 3. æ ¸å¿ƒï¼šæ¯æ—¥æ„å»ºå¤šç©ºç»„åˆ (Simplified Fama-French)
        print("ğŸ§® æ­£åœ¨è®¡ç®—æ¯æ—¥ SMB / HML å› å­...")
        
        # è¿™ç§ groupby å¯èƒ½ä¼šäº§ç”Ÿ warningsï¼Œè¿™æ˜¯æ­£å¸¸çš„
        factors = df_panel.groupby('date').apply(self._calculate_daily_factors)
        
        return factors

    def _load_and_merge_data(self):
        """
        è¯»å–æ‰€æœ‰ CSV å¹¶åˆå¹¶ä¸ºä¸€ä¸ªå¤§çš„ Panel DataFrame
        """
        # --- A. è¯»å–ä»·æ ¼æ•°æ® ---
        price_files = list(self.price_dir.glob("*.csv"))
        if not price_files:
            print("âš ï¸ æœªæ‰¾åˆ°ä»·æ ¼æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œä¸‹è½½å™¨ã€‚")
            return None
            
        dfs = []
        for p in price_files:
            try:
                df = pd.read_csv(p, parse_dates=['date'])
                df['symbol'] = p.stem  # æ–‡ä»¶åå³ä»£ç  (AAPL.csv -> AAPL)
                df = df[['date', 'symbol', 'close']] # åªå–æ”¶ç›˜ä»·
                dfs.append(df)
            except Exception as e:
                print(f"âš ï¸ è¯»å– {p.name} å¤±è´¥: {e}")
        
        if not dfs: return None
        df_prices = pd.concat(dfs)
        
        # --- B. è¯»å–åŸºæœ¬é¢æ•°æ® ---
        fund_files = list(self.fund_dir.glob("*_fundamentals.csv"))
        dfs_fund = []
        for f in fund_files:
            try:
                df = pd.read_csv(f, parse_dates=['date'])
                # æ–‡ä»¶åæ˜¯ AAPL_fundamentals.csv -> æå– AAPL
                symbol = f.name.split('_')[0] 
                df['symbol'] = symbol
                
                # å…¼å®¹æ€§æ£€æŸ¥ï¼šç¡®ä¿æœ‰ shares åˆ—
                if 'shares' not in df.columns:
                    # å¦‚æœä¹‹å‰ FMP çš„æ—§æ•°æ®æ®‹ç•™ï¼Œå¯èƒ½åªæœ‰ marketCap
                    if 'marketCap' in df.columns and 'close' in df.columns:
                        # å°è¯•å€’æ¨ shares (ä¸æ¨èï¼Œä½†ä¸ºäº†å®¹é”™)
                        df['shares'] = df['marketCap'] / df['close'] 
                    else:
                        continue # è·³è¿‡æ— æ•ˆæ•°æ®
                
                # åªå–éœ€è¦çš„åˆ—
                cols_to_keep = ['date', 'symbol', 'book_value', 'shares']
                df = df[[c for c in cols_to_keep if c in df.columns]]
                dfs_fund.append(df)
            except Exception as e:
                print(f"âš ï¸ è¯»å–åŸºæœ¬é¢ {f.name} å¤±è´¥: {e}")
            
        if not dfs_fund:
            print("âš ï¸ æœªæ‰¾åˆ°åŸºæœ¬é¢æ•°æ®ã€‚")
            return None
            
        df_funds = pd.concat(dfs_fund)
        
        # --- C. åˆå¹¶ç­–ç•¥ (Merge Logic) ---
        # ğŸŒŸã€å…³é”®ä¿®å¤ 1ã€‘ï¼špd.merge_asof è¦æ±‚å·¦è¡¨(prices)å¿…é¡»ä¸¥æ ¼æŒ‰ date æ’åº
        # ä¹‹å‰æŒ‰ ['symbol', 'date'] æ’åºä¼šå¯¼è‡´ date ä¸æ˜¯å•è°ƒé€’å¢çš„ï¼Œä»è€ŒæŠ¥é”™
        df_prices = df_prices.sort_values('date')
        df_funds = df_funds.sort_values('date')
        
        # ä½¿ç”¨ merge_asof å°†è´¢æŠ¥æ•°æ®åŒ¹é…åˆ°æ¯å¤©
        df_merge = pd.merge_asof(
            df_prices,
            df_funds,
            on='date',
            by='symbol',
            direction='backward' # ä½¿ç”¨æœ€è¿‘ä¸€æ¬¡å·²çŸ¥çš„è´¢æŠ¥
        )
        
        # --- D. è®¡ç®—è¡ç”ŸæŒ‡æ ‡ (é€‚é… Yahoo æ•°æ®) ---
        # ğŸŒŸã€å…³é”®ä¿®å¤ 2ã€‘ï¼šä½¿ç”¨ shares è®¡ç®—æ¯æ—¥åŠ¨æ€å¸‚å€¼
        if 'shares' in df_merge.columns:
            # Size = æ¯æ—¥è‚¡ä»· * å†å²è‚¡æœ¬
            df_merge['size'] = df_merge['close'] * df_merge['shares']
        else:
            print("âŒ æ•°æ®ä¸­ç¼ºå°‘ 'shares' åˆ—ï¼Œæ— æ³•è®¡ç®—å¸‚å€¼ã€‚")
            return None

        # BM = è´¦é¢ä»·å€¼ / åŠ¨æ€å¸‚å€¼
        df_merge['bm'] = df_merge['book_value'] / df_merge['size']
        
        # æ¸…ç†æ— ç©·å¤§æˆ–ç©ºå€¼
        df_merge.replace([np.inf, -np.inf], np.nan, inplace=True)
        df_merge.dropna(subset=['size', 'bm', 'close'], inplace=True)
        
        # è¿‡æ»¤æ‰å¸‚å€¼è¿‡å°çš„æ•°æ® (ä¾‹å¦‚å°äº 1000 ä¸‡) é˜²æ­¢å™ªéŸ³
        df_merge = df_merge[df_merge['size'] > 1e7]
        
        return df_merge

    def _calculate_daily_factors(self, daily_df):
        """
        æ¯å¤©è¢«è°ƒç”¨ä¸€æ¬¡ã€‚
        """
        # å¦‚æœå½“å¤©çš„è‚¡ç¥¨æ•°é‡å¤ªå°‘ï¼Œæ— æ³•æœ‰æ•ˆåˆ†ç»„ï¼Œè¿”å›ç©º
        # æ—¢ç„¶æˆ‘ä»¬ç”¨äº† nanmeanï¼Œå¯ä»¥ç¨å¾®æ”¾å®½é™åˆ¶ï¼Œåªè¦æœ‰æ•°æ®å°±è¡Œ
        if len(daily_df) < 2: 
            return pd.Series({'SMB': np.nan, 'HML': np.nan})
            
        try:
            # --- 1. Size åˆ†ç»„ (Small vs Big) ---
            median_size = daily_df['size'].median()
            small_cap = daily_df[daily_df['size'] <= median_size]
            big_cap = daily_df[daily_df['size'] > median_size]
            
            # --- 2. Value åˆ†ç»„ (30%, 70%) ---
            bm_30 = daily_df['bm'].quantile(0.3)
            bm_70 = daily_df['bm'].quantile(0.7)
            
            # --- 3. è®¡ç®—å…­ä¸ªç»„åˆçš„å¹³å‡æ”¶ç›Šç‡ ---
            # å¦‚æœæŸç»„ä¸ºç©ºï¼Œmean() ä¼šè¿”å› NaN
            
            # S/L, S/M, S/H
            sl = small_cap[small_cap['bm'] <= bm_30]['ret'].mean()
            sm = small_cap[(small_cap['bm'] > bm_30) & (small_cap['bm'] < bm_70)]['ret'].mean()
            sh = small_cap[small_cap['bm'] >= bm_70]['ret'].mean()
            
            # B/L, B/M, B/H
            bl = big_cap[big_cap['bm'] <= bm_30]['ret'].mean()
            bm = big_cap[(big_cap['bm'] > bm_30) & (big_cap['bm'] < bm_70)]['ret'].mean()
            bh = big_cap[big_cap['bm'] >= bm_70]['ret'].mean()
            
            # --- 4. å› å­æ„å»º (Robust ç‰ˆæœ¬) ---
            # ğŸŒŸ å…³é”®ä¿®æ”¹ï¼šä½¿ç”¨ np.nanmean è‡ªåŠ¨å¿½ç•¥ç©ºå€¼ (NaN)
            # è¿™æ ·å³ä½¿ "Small-Medium" ç»„é‡Œæ²¡è‚¡ç¥¨ï¼Œä¹Ÿèƒ½ç”¨ S/L å’Œ S/H ç®—å‡º SMB
            
            small_ret = np.nanmean([sl, sm, sh])
            big_ret = np.nanmean([bl, bm, bh])
            
            # å¦‚æœ Small æˆ– Big æ•´ä½“éƒ½æ²¡æ•°æ®ï¼Œç»“æœå°±æ˜¯ NaN
            smb = small_ret - big_ret
            
            high_ret = np.nanmean([sh, bh])
            low_ret = np.nanmean([sl, bl])
            
            hml = high_ret - low_ret
            
            return pd.Series({'SMB': smb, 'HML': hml})
            
        except Exception:
            return pd.Series({'SMB': np.nan, 'HML': np.nan})