import os
import logging
import pandas as pd
import requests
import datetime
import pandas_datareader.data as web
from src.data_manager import DataManager
from src.config import DATA_DIR  # ç¡®ä¿å¼•å…¥é…ç½®è·¯å¾„

# ==========================================
# 1. ç½‘ç»œä¸ä»£ç†è®¾ç½® (æ ¹æ®æ‚¨çš„å®é™…æƒ…å†µè°ƒæ•´ç«¯å£)
# ==========================================
PROXY_PORT = 7897 
os.environ["HTTP_PROXY"] = f"http://127.0.0.1:{PROXY_PORT}"
os.environ["HTTPS_PROXY"] = f"http://127.0.0.1:{PROXY_PORT}"

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def get_tickers_from_wiki(url, limit, name):
    """
    é€šç”¨çˆ¬è™«ï¼šä»ç»´åŸºç™¾ç§‘è¡¨æ ¼ä¸­æå–è‚¡ç¥¨ä»£ç 
    """
    print(f"ğŸŒ æ­£åœ¨æŠ“å– [{name}]... ç›®æ ‡æ•°é‡: {limit}")
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        r = requests.get(url, headers=headers, proxies={"http": os.environ["HTTP_PROXY"], "https": os.environ["HTTPS_PROXY"]})
        
        # è§£æè¡¨æ ¼
        tables = pd.read_html(r.text)
        df = tables[0]
        
        # å¯»æ‰¾ä»£ç åˆ— (Symbol æˆ– Ticker symbol)
        col_name = 'Symbol' if 'Symbol' in df.columns else 'Ticker symbol'
        
        # æ¸…æ´—ä»£ç  (æŠŠ BF.B å˜æˆ BF-B)
        tickers = df[col_name].str.replace('.', '-', regex=False).tolist()
        
        # æˆªå–å‰ N ä¸ª
        selected = tickers[:limit]
        print(f"âœ… [{name}] æŠ“å–æˆåŠŸ! å®é™…è·å–: {len(selected)} åª")
        return selected
        
    except Exception as e:
        print(f"âš ï¸ [{name}] æŠ“å–å¤±è´¥: {e}")
        return []

def fetch_and_save_online_factors(db):
    """
    å°è¯•åœ¨çº¿ä¸‹è½½ Fama-French å› å­å¹¶ä¿å­˜
    """
    print("\nğŸŒ [æ–¹å¼1] æ­£åœ¨å°è¯•åœ¨çº¿ä¸‹è½½ Fama-French å› å­ (Kenneth French Library)...")
    start_date = "2000-01-01"
    end_date = datetime.datetime.now().strftime("%Y-%m-%d")

    try:
        # 1. ä¸‹è½½ Fama-French 3å› å­ (Mkt-RF, SMB, HML)
        ff3_data = web.DataReader("F-F_Research_Data_Factors_daily", "famafrench", start=start_date, end=end_date)
        df_ff3 = ff3_data[0]
        
        # 2. ä¸‹è½½ åŠ¨é‡å› å­ (Momentum)
        mom_data = web.DataReader("F-F_Momentum_Factor_daily", "famafrench", start=start_date, end=end_date)
        df_mom = mom_data[0]
        
        # 3. åˆå¹¶æ•°æ®å¹¶é™¤ä»¥100 (åŸå§‹æ•°æ®æ˜¯ç™¾åˆ†æ¯”æ•´æ•°)
        df_merged = df_ff3.join(df_mom, how="inner") / 100.0
        
        # 4. é‡å‘½ååˆ—ä»¥åŒ¹é…æ•°æ®åº“ schema
        df_merged.rename(columns={
            'Mkt-RF': 'mkt',
            'SMB': 'smb',
            'HML': 'hml',
            'Mom   ': 'mom'
        }, inplace=True)
        
        # æ¸…æ´—åˆ—å
        df_merged.columns = [c.strip().lower() for c in df_merged.columns]
        
        # 5. å­˜å…¥æ•°æ®åº“
        required_cols = ['mkt', 'smb', 'hml', 'mom']
        if all(col in df_merged.columns for col in required_cols):
            db.save_factors(df_merged[required_cols])
            print(f"âœ… åœ¨çº¿å› å­æ›´æ–°æˆåŠŸ! æ—¶é—´èŒƒå›´: {df_merged.index[0].date()} -> {df_merged.index[-1].date()}")
            return True
        else:
            print("âš ï¸ åœ¨çº¿æ•°æ®åˆ—åä¸åŒ¹é…ã€‚")
            return False
            
    except Exception as e:
        print(f"âŒ åœ¨çº¿ä¸‹è½½å¤±è´¥: {e}")
        return False

def load_local_factors(db):
    """
    è¯»å–æœ¬åœ° CSV å› å­æ–‡ä»¶ä½œä¸ºå¤‡ç”¨
    """
    print("\nğŸ“‚ [æ–¹å¼2] æ­£åœ¨å°è¯•è¯»å–æœ¬åœ°å› å­æ–‡ä»¶ (data/my_ff_factors.csv)...")
    factor_path = DATA_DIR / "my_ff_factors.csv"
    
    if not factor_path.exists():
        print(f"âš ï¸ æœªæ‰¾åˆ°æœ¬åœ°å› å­æ–‡ä»¶: {factor_path}")
        return

    try:
        df = pd.read_csv(factor_path)
        # æ¸…æ´—åˆ—å
        df.columns = [c.lower().strip() for c in df.columns]
        
        # å¤„ç†æ—¥æœŸ
        if 'date' in df.columns:
            df['date'] = pd.to_datetime(df['date'])
            df.set_index('date', inplace=True)
        else:
            try: df.index = pd.to_datetime(df.index)
            except: 
                print("âŒ æœ¬åœ°æ–‡ä»¶æ—¥æœŸè§£æå¤±è´¥")
                return

        # ç®€å•çš„åˆ—åæ˜ å°„å…¼å®¹
        rename_map = {}
        for col in df.columns:
            if 'mkt' in col: rename_map[col] = 'mkt'
            elif 'smb' in col: rename_map[col] = 'smb'
            elif 'hml' in col: rename_map[col] = 'hml'
            elif 'mom' in col: rename_map[col] = 'mom'
        df.rename(columns=rename_map, inplace=True)
        
        valid_cols = [c for c in ['smb', 'hml', 'mom', 'mkt'] if c in df.columns]
        if valid_cols:
            db.save_factors(df[valid_cols])
            print(f"âœ… æœ¬åœ°å› å­åŠ è½½æˆåŠŸ! åŒ…å«åˆ—: {valid_cols}")
        else:
            print("âŒ æœ¬åœ°æ–‡ä»¶ç¼ºå°‘å¿…è¦çš„å› å­åˆ—ã€‚")
            
    except Exception as e:
        print(f"âŒ æœ¬åœ°åŠ è½½å‡ºé”™: {e}")

def main():
    print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–æ•°æ®åº“...")
    db = DataManager()
    
    # ==========================================
    # è®¾å®šè‚¡ç¥¨æ•°é‡
    # ==========================================
    NUM_LARGE_CAP = 500
    NUM_SMALL_CAP = 600

    # 1. æŠ“å–å¤§ç›˜è‚¡
    url_sp500 = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
    large_caps = get_tickers_from_wiki(url_sp500, limit=NUM_LARGE_CAP, name="S&P 500")
    if not large_caps:
        large_caps = ['AAPL', 'MSFT', 'NVDA', 'GOOGL', 'AMZN', 'META', 'TSLA', 'JPM', 'V', 'LLY']

    # 2. æŠ“å–å°ç›˜è‚¡
    url_sp600 = "https://en.wikipedia.org/wiki/List_of_S%26P_600_companies"
    small_caps = get_tickers_from_wiki(url_sp600, limit=NUM_SMALL_CAP, name="S&P 600")

    # 3. æ ¸å¿ƒæ ‡çš„
    essential_tickers = ['SPY', 'QQQ', 'TLT', 'GLD', 'IWM', 'AAPL', 'MSFT', 'NVDA', 'JPM']
    
    # 4. åˆå¹¶å»é‡
    final_tickers = list(set(large_caps + small_caps + essential_tickers))
    
    print("-" * 50)
    print(f"ğŸ”¥ æ€»å…±éœ€ä¸‹è½½: {len(final_tickers)} åªè‚¡ç¥¨")
    print("-" * 50)
    
    # 5. æ›´æ–°è‚¡ä»·æ•°æ®
    db.update_stock_data(final_tickers)
    
    # ==========================================
    # âœ… 6. å…³é”®ä¿®å¤ï¼šæ›´æ–°å› å­æ•°æ® (ä¼˜å…ˆåœ¨çº¿ï¼Œå¤±è´¥åˆ™æœ¬åœ°)
    # ==========================================
    success = fetch_and_save_online_factors(db)
    if not success:
        load_local_factors(db)
    
    db.close()
    print("\nâœ… æ•°æ®åº“åˆå§‹åŒ–å…¨éƒ¨å®Œæˆï¼è¯·è¿è¡Œ 'python main.py'ã€‚")

if __name__ == "__main__":
    main()